{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># **Ciência dos Dados** <font color=green>- Projeto 2</font>\n",
    "   #### <font color=grey> Beatriz Mie Kotsubo Kuwabara, <p>Lucas Nicascio dos Santos,</p>Manuela Castilla Russo Correa <p> </font>\n",
    "\n",
    "## Classificador Automático de Sentimento com Vários Níveis de Relevância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificação de informação se dá pela categorização de uma grande base de dados. Atualmente, uma grande fonte de dados e consequentemente de informações que ajudam a compreender comportamentos e tendências da sociedade são as redes sociais, como o Twitter. Nesse projeto, utilizando-se da API do Twitter, tivemos acesso a alguns recentes tweets publicados em inglês na plataforma de forma a analisar as reações dos usuários à marca Nike ultimamente dado o lançamento de uma recente campanha protagonizada pelo ex-jogador da NFL Colin Kaepernick, gerando reações contra e a favor à marca. Na base da dados foi classificado se os tweets eram muito irrelevantes, irrelevantes, neutro, relevantes ou muito relevantes. \n",
    "\n",
    "<p>A implementação do \"machine learning\" por meio do classificador Naive Bayes utiliza-se de uma base de 300 tweets para o treinamento do código para uma posterior verificação com diferentes tweets em uma base de teste.</p>\n",
    "\n",
    "<p>O classificador Naive Bayes é um algoritmo para a tarefa de classificação utilizando o teorema de Bayes, que é uma equação que descreve a relação de probabilidades condicionais de grandezas estatísticas. O classificador fornece ótimos resultados quando o usamos para análise de dados textuais.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCEDIMENTOS PARA A CRIAÇÃO DO CÓDIGO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Limpamos os tweets\n",
    "##### Para poder mexer e manipular os dados, tiramos as pontuções, palavras de duas letras (já que uma palavra tão pequena não será irrelevante em relação ao sentimento dos usuários). Além disso, separamos os emojis das palavras:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente importamos para poder realizar o código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from emoji import UNICODE_EMOJI\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemos os arquivos do excel:\n",
    "\n",
    "Criamos três colunas na qual seriam:\n",
    "\n",
    "(1) Os tweets \n",
    "\n",
    "(2) Classificação apenas entre relevante ou irrelevante\n",
    "\n",
    "(2) Classificação entre os níveis de sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Valor_(R(1)_I(0))</th>\n",
       "      <th>Níveis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>save big with joyhunt-up to 80% off rpp on gre...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @virgilableaux: hi. former us navy sailor h...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Valor_(R(1)_I(0))  \\\n",
       "0  save big with joyhunt-up to 80% off rpp on gre...                  1   \n",
       "1  rt @virgilableaux: hi. former us navy sailor h...                  1   \n",
       "\n",
       "   Níveis  \n",
       "0       2  \n",
       "1       4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nike = pd.read_excel('1537437860647_tweets_nike_201809042210.xlsx', sheet_name = 0)\n",
    "nike_treinamento = nike[\"Treinamento\"]\n",
    "nike.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Níveis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>save big with joyhuntup to 80 off rpp on great...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt virgilableaux hi former us navy sailor here...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boycottnike i think a great big thank you nike...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt thedonholly if you plan on boycotting nike ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt thedonholly if you plan on boycotting nike ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Níveis\n",
       "0  save big with joyhuntup to 80 off rpp on great...       2\n",
       "1  rt virgilableaux hi former us navy sailor here...       4\n",
       "2  boycottnike i think a great big thank you nike...       4\n",
       "3  rt thedonholly if you plan on boycotting nike ...       3\n",
       "4  rt thedonholly if you plan on boycotting nike ...       3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "pontu = string.punctuation\n",
    "\n",
    "#criação de lista para tirar os tabs e os enters\n",
    "pont =[\"\\n\", \"\\t\"]\n",
    "\n",
    "#simplificação para pegar o dataframde dos tweets\n",
    "tweet = nike[\"Treinamento\"]\n",
    "\n",
    "### limpando os tweets\n",
    "tweets_limpos = []\n",
    "\n",
    "for frase in tweet:\n",
    "    x = \"\"\n",
    "    for m in frase:\n",
    "        if m in UNICODE_EMOJI:\n",
    "            x = x + \" \" + m + \" \"\n",
    "        elif m in pont:\n",
    "            x += \" \"\n",
    "        elif m not in pontu:\n",
    "            x += m\n",
    "    tweets_limpos.append(x)\n",
    "\n",
    "# criando um dataframe com os tweets limpos\n",
    "nike_limpinho = pd.DataFrame()\n",
    "nike_limpinho[\"tweets\"]= tweets_limpos\n",
    "nike_limpinho[\"Níveis\"] = nike[\"Níveis\"]\n",
    "\n",
    "nike_limpinho.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Níveis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>save big with joyhuntup off rpp great brands s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virgilableaux former navy sailor here wonderin...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boycottnike think great big thank you nike fro...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thedonholly you plan boycotting nike will disp...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thedonholly you plan boycotting nike will disp...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Níveis\n",
       "0  save big with joyhuntup off rpp great brands s...       2\n",
       "1  virgilableaux former navy sailor here wonderin...       4\n",
       "2  boycottnike think great big thank you nike fro...       4\n",
       "3  thedonholly you plan boycotting nike will disp...       3\n",
       "4  thedonholly you plan boycotting nike will disp...       3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## limpar os nomes:\n",
    "    # tirar tudo que é irrelevante para minha pesquisa e para descobrir a probabilidade como: @,\n",
    "    # palavras com poucas letras, #, link(site).\n",
    "\n",
    "tweet_limpos =[]\n",
    "y = \" \"\n",
    "for tweet in nike_limpinho[\"tweets\"]:\n",
    "    limpao = [] \n",
    "    splitei = tweet.split(\" \")\n",
    "    for palavra in splitei:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            limpao.append(palavra)\n",
    "        elif len(palavra)> 2 and palavra[0]!=\"@\" and palavra[0]!=\"#\" and palavra[:4] !=\"http\":\n",
    "            limpao.append(palavra)\n",
    "    tweet_limpos.append(y.join(limpao))\n",
    "    \n",
    "nike_limpao = pd.DataFrame()\n",
    "nike_limpao[\"tweets\"]= tweet_limpos\n",
    "nike_limpao[\"Níveis\"] = nike[\"Níveis\"]\n",
    "\n",
    "nike_limpao.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Preparando os dados para implementação de Bayes\n",
    "##### Primeiramente criamos uma lista em que selecionava todas as palavras sem repetição, tendo um total de palavras em existentes em todos os tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = []\n",
    "for e in nike_limpao[\"tweets\"]: \n",
    "    y = e.split()\n",
    "    for m in y:\n",
    "        if m not in palavras: \n",
    "            palavras.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Depois disso, criamos um contador de cada nível em que contava o número de vezes que aparecia tweets (palavras) em relevantes e irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIrrel = 0\n",
    "Irrel = 0\n",
    "Neutro = 0\n",
    "Rel=0\n",
    "MRel = 0\n",
    "for i in range(len(nike_limpao)):\n",
    "    linha = nike_limpao[\"tweets\"][i].split(\" \")\n",
    "    for m in linha:\n",
    "        if nike_limpao[\"Níveis\"][i] == 0:\n",
    "            MIrrel +=1\n",
    "        elif nike_limpao[\"Níveis\"][i]== 1:\n",
    "            Irrel+=1\n",
    "        elif nike_limpao[\"Níveis\"][i]== 2:\n",
    "            Neutro+=1\n",
    "        elif nike_limpao[\"Níveis\"][i]== 3:\n",
    "            Rel+=1\n",
    "        else:\n",
    "            MRel +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Após isso, calculamos a frequência com a qual cada palavra aparece em cada nível de classificação\n",
    "\n",
    "Para isso, criamos um dicionário. Depois disso, fizemos um for para que passasse em cada palavra de cada tweet adicionando a palavra pelo menos uma vez em cada dicionário (já iniciando o laplace smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_MR = {}\n",
    "freq_R = {}\n",
    "freq_MI = {}\n",
    "freq_I = {}\n",
    "freq_N = {}\n",
    "\n",
    "for palavra in palavras:\n",
    "    freq_MR[palavra] = 1\n",
    "    freq_R[palavra] = 1\n",
    "    freq_MI[palavra] = 1\n",
    "    freq_I[palavra] = 1\n",
    "    freq_N[palavra] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Depois de adicionar pelo menos uma vez a palavra em cada dicionário, passamos novamente pelas palavras,mas agora adicionando nos dicionários de acordo o nível em que a palavra estava em um tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(nike_limpao)):\n",
    "    palavra = nike_limpao[\"tweets\"][i].split(\" \")\n",
    "    for m in palavra:\n",
    "        if nike_limpao[\"Níveis\"][i]== 0:\n",
    "            freq_MI[m]+=1\n",
    "        elif nike_limpao[\"Níveis\"][i]== 1:\n",
    "            freq_I[m]+=1\n",
    "        elif nike_limpao[\"Níveis\"][i]== 2:\n",
    "            freq_N[m]+=1\n",
    "        elif nike_limpao[\"Níveis\"][i]== 3:\n",
    "            freq_R[m]+=1\n",
    "        else:\n",
    "            freq_MR[m]+=1\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Implementando a Naive-Bayes\n",
    "\n",
    "#### Primeiramente calculamos a probabilidade de uma palavra sabendo seu nível:\n",
    "- P(palavra|Muito relevante)\n",
    "- P(palavra|Relevante)\n",
    "- P(palavra|Neutro)\n",
    "- P(palavra|Irrelevante)\n",
    "- P(palavra|Muito irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilidade de ser relevante dada cada palavra\n",
    "\n",
    "prob_mi ={}\n",
    "prob_i ={}\n",
    "prob_n ={}\n",
    "prob_r = {}\n",
    "prob_mr ={}\n",
    "\n",
    "for palavra in palavras:\n",
    "    prob_mi[palavra]= freq_MI[palavra]/(len(palavras)+MIrrel)\n",
    "    prob_i[palavra]= freq_I[palavra]/(len(palavras)+Irrel)\n",
    "    prob_n[palavra]= freq_N[palavra]/(len(palavras)+Neutro)\n",
    "    prob_r[palavra]= freq_R[palavra]/(len(palavras)+Rel)\n",
    "    prob_mr[palavra]= freq_MR[palavra]/(len(palavras)+MRel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Calculamos agora a probabilidade de ser relevante dado cada tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "m_irrelevante = 0\n",
    "irrelevante = 0\n",
    "neutro=0\n",
    "relevante = 0\n",
    "m_relevante =0\n",
    "\n",
    "for p in nike_limpao[\"Níveis\"]:\n",
    "    if p ==0:\n",
    "        m_irrelevante+=1\n",
    "    elif p ==1:\n",
    "        irrelevante+=1\n",
    "    elif p ==2:\n",
    "        neutro+=1\n",
    "    elif p ==3:\n",
    "        relevante+=1\n",
    "    else:\n",
    "        m_relevante +=1\n",
    "        \n",
    "pMI = m_irrelevante/len(nike_limpao[\"Níveis\"])\n",
    "pI = irrelevante/len(nike_limpao[\"Níveis\"])\n",
    "pN = neutro/len(nike_limpao[\"Níveis\"])\n",
    "pR = relevante/len(nike_limpao[\"Níveis\"])\n",
    "pMR = m_relevante/len(nike_limpao[\"Níveis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Iniciando com o Teste\n",
    "### Limpeza dos tweets\n",
    "##### Agora iniciamos com a parte Teste. Para isso, é preciso realizar o mesmo processo de limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo a segunda página para ir ao teste\n",
    "teste = pd.read_excel('1537437860647_tweets_nike_201809042210.xlsx', sheet_name = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Níveis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt jamiesundays nike looking at the white peop...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump weighs in on nikes kaepernick deal i thi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt rafaelshimunov im finally cutting out the n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear nike i am not going to boycott you becaus...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt lindsaytuten anyone who doesn’t want their ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Níveis\n",
       "0  rt jamiesundays nike looking at the white peop...       4\n",
       "1  trump weighs in on nikes kaepernick deal i thi...       3\n",
       "2  rt rafaelshimunov im finally cutting out the n...       3\n",
       "3  dear nike i am not going to boycott you becaus...       3\n",
       "4  rt lindsaytuten anyone who doesn’t want their ...       3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#criação de lista para tirar os tabs e os enters\n",
    "pont =[\"\\n\", \"\\t\"]\n",
    "\n",
    "#simplificação para pegar o dataframde dos tweets\n",
    "tweet = teste[\"Teste\"]\n",
    "\n",
    "### limpando os tweets\n",
    "tweets_limpos = []\n",
    "\n",
    "for frase in tweet:\n",
    "    x = \"\"\n",
    "    for m in frase:\n",
    "        if m in UNICODE_EMOJI:\n",
    "            x = x + \" \" + m + \" \"\n",
    "        elif m in pont:\n",
    "            x += \" \"\n",
    "        elif m not in pontu:\n",
    "            x += m\n",
    "    tweets_limpos.append(x)\n",
    "\n",
    "# criando um dataframe com os tweets limpos\n",
    "nike_limpinho = pd.DataFrame()\n",
    "nike_limpinho[\"tweets\"]= tweets_limpos\n",
    "nike_limpinho[\"Níveis\"] = teste[\"Níveis\"]\n",
    "\n",
    "nike_limpinho.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Níveis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jamiesundays nike looking the white people des...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump weighs nikes kaepernick deal think its t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rafaelshimunov finally cutting out the nike lo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear nike not going boycott you because just s...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lindsaytuten anyone who doesn’t want their nik...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Níveis\n",
       "0  jamiesundays nike looking the white people des...       4\n",
       "1  trump weighs nikes kaepernick deal think its t...       3\n",
       "2  rafaelshimunov finally cutting out the nike lo...       3\n",
       "3  dear nike not going boycott you because just s...       3\n",
       "4  lindsaytuten anyone who doesn’t want their nik...       3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# código para fazer o programa classificar os tweets a partir da probabilidade\n",
    "\n",
    "tweet_limpos =[]\n",
    "y = \" \"\n",
    "for tweet in nike_limpinho[\"tweets\"]:\n",
    "    limpao = [] \n",
    "    splitei = tweet.split(\" \")\n",
    "    for palavra in splitei:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            limpao.append(palavra)\n",
    "        elif len(palavra)> 2 and palavra[0]!=\"@\" and palavra[0]!=\"#\" and palavra[:4] !=\"http\":\n",
    "            limpao.append(palavra)\n",
    "    tweet_limpos.append(y.join(limpao))\n",
    "    \n",
    "nike_limpao = pd.DataFrame()\n",
    "nike_limpao[\"tweets\"]= tweet_limpos\n",
    "nike_limpao[\"Níveis\"] = teste[\"Níveis\"]\n",
    "\n",
    "nike_limpao.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Finalizando a Naive Bayes\n",
    "##### Por fim, juntamos os dados fazendo então o produto de P(frase|rel) com P(Rel), criando então o programa na qual este estima o nível do tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Níveis</th>\n",
       "      <th>Chute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jamiesundays nike looking the white people des...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump weighs nikes kaepernick deal think its t...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rafaelshimunov finally cutting out the nike lo...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear nike not going boycott you because just s...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lindsaytuten anyone who doesn’t want their nik...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Níveis  Chute\n",
       "0  jamiesundays nike looking the white people des...       4      3\n",
       "1  trump weighs nikes kaepernick deal think its t...       3      4\n",
       "2  rafaelshimunov finally cutting out the nike lo...       3      4\n",
       "3  dear nike not going boycott you because just s...       3      3\n",
       "4  lindsaytuten anyone who doesn’t want their nik...       3      3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fazendo P(frase|rel) * P(Rel)\n",
    "chute = []\n",
    "\n",
    "for frase in nike_limpao[\"tweets\"]:\n",
    "    pMI_t = 1\n",
    "    pI_t = 1\n",
    "    pN_t = 1\n",
    "    pR_t= 1\n",
    "    pMR_t = 1\n",
    "    y = frase.split(\" \")\n",
    "    for palavra in y:\n",
    "        \n",
    "        if palavra in prob_mi:\n",
    "            pMI_t *= prob_mi[palavra]\n",
    "        else:\n",
    "            pMI_t *= 1/ (len(palavras)+MIrrel)\n",
    "        \n",
    "        if palavra in prob_i:\n",
    "            pI_t *= prob_i[palavra]\n",
    "        else:\n",
    "            pI_t *= 1/ (len(palavras)+Irrel)\n",
    "            \n",
    "        if palavra in prob_n:\n",
    "            pN_t *= prob_n[palavra]\n",
    "        else:\n",
    "            pN_t *= 1/ (len(palavras)+Neutro)\n",
    "            \n",
    "        if palavra in prob_r:\n",
    "            pR_t*= prob_r[palavra]\n",
    "        else:\n",
    "            pR_t *= 1/(len(palavra)+Rel)\n",
    "            \n",
    "        if palavra in prob_mr:\n",
    "            pMR_t *= prob_mr[palavra]\n",
    "        else:\n",
    "            pMR_t *= 1/ (len(palavras)+MRel)\n",
    "\n",
    "  \n",
    "    PMIR = (pMI*pMI_t)\n",
    "    PIR =(pI*pI_t)\n",
    "    PN = (pN*pN_t)\n",
    "    PR =( pR*pR_t)\n",
    "    PMR = (pMR*pMR_t)\n",
    "    \n",
    "    if PMR >= PR and PMR>=PN and PMR>=PIR and PMR>=PMIR:\n",
    "        chute.append(4)\n",
    "        \n",
    "    elif PR>=PN and PR>=PIR and PR>=PMIR:\n",
    "        chute.append(3)\n",
    "        \n",
    "    elif PN>=PIR and PN>=PMIR:\n",
    "        chute.append(2)\n",
    "        \n",
    "    elif PIR>=PMIR:\n",
    "        chute.append(1)\n",
    "        \n",
    "    else:\n",
    "        chute.append(0)\n",
    "        \n",
    "        \n",
    "# adicionando essa coluna ao nosso dataframe\n",
    "\n",
    "nike_limpao[\"Chute\"] = chute\n",
    "nike_limpao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparando a classificação do teste e do treinamento\n",
    "\n",
    "zero = nike_limpao.loc[(nike_limpao[\"Níveis\"]==0)&(nike_limpao[\"Chute\"]==0), [\"Níveis\", \"Chute\"]]\n",
    "zeroC = nike_limpao.loc[(nike_limpao[\"Níveis\"]!=0)&(nike_limpao[\"Chute\"]==0), [\"Níveis\", \"Chute\"]]\n",
    "\n",
    "um = nike_limpao.loc[(nike_limpao[\"Níveis\"]==1)&(nike_limpao[\"Chute\"]==1), [\"Níveis\", \"Chute\"]]\n",
    "umC = nike_limpao.loc[(nike_limpao[\"Níveis\"]!=1)&(nike_limpao[\"Chute\"]==1), [\"Níveis\", \"Chute\"]]\n",
    "\n",
    "dois = nike_limpao.loc[(nike_limpao[\"Níveis\"]==2)&(nike_limpao[\"Chute\"]==2), [\"Níveis\", \"Chute\"]]\n",
    "doisC = nike_limpao.loc[(nike_limpao[\"Níveis\"]!=2)&(nike_limpao[\"Chute\"]==2), [\"Níveis\", \"Chute\"]]\n",
    "\n",
    "tres = nike_limpao.loc[(nike_limpao[\"Níveis\"]==3)&(nike_limpao[\"Chute\"]==3), [\"Níveis\", \"Chute\"]]\n",
    "tresC= nike_limpao.loc[(nike_limpao[\"Níveis\"]!=3)&(nike_limpao[\"Chute\"]==3), [\"Níveis\", \"Chute\"]]\n",
    "\n",
    "quatro= nike_limpao.loc[(nike_limpao[\"Níveis\"]==4)&(nike_limpao[\"Chute\"]==4), [\"Níveis\", \"Chute\"]]\n",
    "quatroC = nike_limpao.loc[(nike_limpao[\"Níveis\"]!=4)&(nike_limpao[\"Chute\"]==4), [\"Níveis\", \"Chute\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  4  0]\n",
      " [ 0  0  0  2  0]\n",
      " [ 0  0  2  5  0]\n",
      " [ 0  0 11 91 47]\n",
      " [ 0  0  0 27 11]]\n"
     ]
    }
   ],
   "source": [
    "#fazendo uma matriz de confusão\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(nike_limpao[\"Níveis\"], nike_limpao[\"Chute\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predito</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.065</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.290</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predito      2      3      4    All\n",
       "Real                               \n",
       "0        0.000  0.020  0.000  0.020\n",
       "1        0.000  0.010  0.000  0.010\n",
       "2        0.010  0.025  0.000  0.035\n",
       "3        0.055  0.455  0.235  0.745\n",
       "4        0.000  0.135  0.055  0.190\n",
       "All      0.065  0.645  0.290  1.000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz = pd.crosstab(nike_limpao[\"Níveis\"], nike_limpao[\"Chute\"], rownames=[\"Real\"], colnames=[\"Predito\"], margins=True, normalize=True)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de muitos relevantes verdadeiros: 0%\n",
      "Porcentagem de relevantes verdadeiros: 0%\n",
      "Porcentagem de neutros verdadeiros: 1.0%\n",
      "Porcentagem de relevantes verdadeiros: 45.5%\n",
      "Porcentagem de muito relevante falsos: 5.5%\n"
     ]
    }
   ],
   "source": [
    "#calculando a probabilidade de positivos verdadeiros, positivos falsos, negativos verdadeiros e negativos falsos totais do classificador\n",
    "\n",
    "print(\"Porcentagem de muitos relevantes verdadeiros: 0%\")\n",
    "print(\"Porcentagem de relevantes verdadeiros: 0%\")\n",
    "print(\"Porcentagem de neutros verdadeiros: {0}%\".format((matriz.loc[2, 2])*100))\n",
    "print(\"Porcentagem de relevantes verdadeiros: {0}%\".format((matriz.loc[3, 3])*100))\n",
    "print(\"Porcentagem de muito relevante falsos: {0}%\".format((matriz.loc[4, 4])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
