{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gfdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeiramente importamos para poder realizar o código\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from emoji import UNICODE_EMOJI\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Valor_(R(1)_I(0))</th>\n",
       "      <th>Positivo(1)/Negativo(0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@floydy1983  save big with joyhunt-up to 80% o...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @virgilableaux: hi. former us navy sailor h...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Valor_(R(1)_I(0))  \\\n",
       "0  @floydy1983  save big with joyhunt-up to 80% o...                  1   \n",
       "1  rt @virgilableaux: hi. former us navy sailor h...                  1   \n",
       "\n",
       "   Positivo(1)/Negativo(0)  \n",
       "0                      1.0  \n",
       "1                      1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nike = pd.read_excel('tweets_nike_201809042210.xlsx', sheet_name = 0)\n",
    "nike_treinamento = nike[\"Treinamento\"]\n",
    "nike.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>floydy1983  save big with joyhuntup to 80 off ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt virgilableaux hi former us navy sailor here...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boycottnike i think a great big thank you nike...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt thedonholly if you plan on boycotting nike ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt tonestradamus when they start boycotting ni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Relevância\n",
       "0  floydy1983  save big with joyhuntup to 80 off ...           1\n",
       "1  rt virgilableaux hi former us navy sailor here...           1\n",
       "2  boycottnike i think a great big thank you nike...           1\n",
       "3  rt thedonholly if you plan on boycotting nike ...           1\n",
       "4  rt tonestradamus when they start boycotting ni...           1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "pontu = string.punctuation\n",
    "\n",
    "\n",
    "#criação de lista para tirar os tabs e os enters\n",
    "pont =[\"\\n\", \"\\t\"]\n",
    "\n",
    "#simplificação para pegar o dataframde dos tweets\n",
    "tweet = nike[\"Treinamento\"]\n",
    "\n",
    "### limpando os tweets\n",
    "tweets_limpos = []\n",
    "\n",
    "for frase in tweet:\n",
    "    x = \"\"\n",
    "    for m in frase:\n",
    "        if m in UNICODE_EMOJI:\n",
    "            x = x + \" \" + m + \" \"\n",
    "        elif m in pont:\n",
    "            x += \" \"\n",
    "        elif m not in pontu:\n",
    "            x += m\n",
    "    tweets_limpos.append(x)\n",
    "\n",
    "# criando um dataframe com os tweets limpos\n",
    "nike_limpinho = pd.DataFrame()\n",
    "nike_limpinho[\"tweets\"]= tweets_limpos\n",
    "nike_limpinho[\"Relevância\"] = nike[\"Valor_(R(1)_I(0))\"]\n",
    "\n",
    "nike_limpinho.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>floydy1983 save big with joyhuntup off rpp gre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virgilableaux former navy sailor here wonderin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boycottnike think great big thank you nike fro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thedonholly you plan boycotting nike will disp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tonestradamus when they start boycotting nike ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Relevância\n",
       "0  floydy1983 save big with joyhuntup off rpp gre...           1\n",
       "1  virgilableaux former navy sailor here wonderin...           1\n",
       "2  boycottnike think great big thank you nike fro...           1\n",
       "3  thedonholly you plan boycotting nike will disp...           1\n",
       "4  tonestradamus when they start boycotting nike ...           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## limpar os nomes:\n",
    "    # tirar tudo que é irrelevante para minha pesquisa e para descobrir a probabilidade como: @,\n",
    "    # palavras com poucas letras, #, link(site).\n",
    "\n",
    "tweet_limpos =[]\n",
    "y = \" \"\n",
    "for tweet in nike_limpinho[\"tweets\"]:\n",
    "    limpao = [] \n",
    "    splitei = tweet.split(\" \")\n",
    "    for palavra in splitei:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            limpao.append(palavra)\n",
    "        elif len(palavra)> 2 and palavra[0]!=\"@\" and palavra[0]!=\"#\" and palavra[:4] !=\"http\":\n",
    "            limpao.append(palavra)\n",
    "    tweet_limpos.append(y.join(limpao))\n",
    "    \n",
    "nike_limpao = pd.DataFrame()\n",
    "nike_limpao[\"tweets\"]= tweet_limpos\n",
    "nike_limpao[\"Relevância\"] = nike[\"Valor_(R(1)_I(0))\"]\n",
    "\n",
    "nike_limpao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = []\n",
    "\n",
    "#adicionando todas palavras que foram recolhidas pelo tweet na lista\n",
    "for e in nike_limpao[\"tweets\"]: \n",
    "    y = e.split()\n",
    "    for m in y:\n",
    "        if m not in palavras: \n",
    "            palavras.append(m)\n",
    "\n",
    "#adicionar a quantidade de vezes que apareceu tweets relevantes e irrelevantes\n",
    "Rel = 0\n",
    "Irrel = 0\n",
    "for i in range(len(nike_limpao)):\n",
    "    linha = nike_limpao[\"tweets\"][i].split(\" \")\n",
    "    for m in linha:\n",
    "        if nike_limpao[\"Relevância\"][i] == 0:\n",
    "            Irrel +=1\n",
    "        else:\n",
    "            Rel +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adicionando pelo menos as palavras uma vez no dicionario para que quando for fazer vezes nunca multiplica por zero\n",
    "\n",
    "freq_rel = {}\n",
    "freq_irrel = {}\n",
    "\n",
    "for palavra in palavras:\n",
    "    freq_rel[palavra] = 1\n",
    "    freq_irrel[palavra] = 1\n",
    "\n",
    "for i in range(len(nike_limpao)):\n",
    "    palavra = nike_limpao[\"tweets\"][i].split(\" \")\n",
    "    for m in palavra:\n",
    "        if nike_limpao[\"Relevância\"][i]== 0:\n",
    "            freq_irrel[m]+=1\n",
    "        else:\n",
    "            freq_rel[m]+=1\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilidade de ser relevante dada cada palavra\n",
    "\n",
    "prob_i ={}\n",
    "prob_r = {}\n",
    "\n",
    "for palavra in palavras:\n",
    "    prob_r[palavra]= freq_rel[palavra]/(len(palavras)+Rel)\n",
    "    prob_i[palavra]= freq_irrel[palavra]/(len(palavras)+Irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevante = 0\n",
    "relevante = 0\n",
    "\n",
    "for p in nike_limpao[\"Relevância\"]:\n",
    "    if p ==0:\n",
    "        irrelevante+=1\n",
    "    else:\n",
    "        relevante +=1\n",
    "        \n",
    "pI = irrelevante/len(nike_limpao[\"Relevância\"])\n",
    "pR = relevante/len(nike_limpao[\"Relevância\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.read_excel('tweets_nike_201809042210.xlsx', sheet_name = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt jamiesundays nike looking at the white peop...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump weighs in on nikes kaepernick deal i thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt rafaelshimunov im finally cutting out the n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear nike i am not going to boycott you becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt lindsaytuten anyone who doesn’t want their ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Relevância\n",
       "0  rt jamiesundays nike looking at the white peop...           1\n",
       "1  trump weighs in on nikes kaepernick deal i thi...           1\n",
       "2  rt rafaelshimunov im finally cutting out the n...           1\n",
       "3  dear nike i am not going to boycott you becaus...           1\n",
       "4  rt lindsaytuten anyone who doesn’t want their ...           1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#criação de lista para tirar os tabs e os enters\n",
    "pont =[\"\\n\", \"\\t\"]\n",
    "\n",
    "#simplificação para pegar o dataframde dos tweets\n",
    "tweet = teste[\"Teste\"]\n",
    "\n",
    "### limpando os tweets\n",
    "tweets_limpos = []\n",
    "\n",
    "for frase in tweet:\n",
    "    x = \"\"\n",
    "    for m in frase:\n",
    "        if m in UNICODE_EMOJI:\n",
    "            x = x + \" \" + m + \" \"\n",
    "        elif m in pont:\n",
    "            x += \" \"\n",
    "        elif m not in pontu:\n",
    "            x += m\n",
    "    tweets_limpos.append(x)\n",
    "\n",
    "# criando um dataframe com os tweets limpos\n",
    "nike_limpinho = pd.DataFrame()\n",
    "nike_limpinho[\"tweets\"]= tweets_limpos\n",
    "nike_limpinho[\"Relevância\"] = teste[\"Valor_(R(1)_I(0))\"]\n",
    "\n",
    "nike_limpinho.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jamiesundays nike looking the white people des...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump weighs nikes kaepernick deal think its t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rafaelshimunov finally cutting out the nike lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear nike not going boycott you because just s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lindsaytuten anyone who doesn’t want their nik...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  Relevância\n",
       "0  jamiesundays nike looking the white people des...           1\n",
       "1  trump weighs nikes kaepernick deal think its t...           1\n",
       "2  rafaelshimunov finally cutting out the nike lo...           1\n",
       "3  dear nike not going boycott you because just s...           1\n",
       "4  lindsaytuten anyone who doesn’t want their nik...           1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_limpos =[]\n",
    "y = \" \"\n",
    "for tweet in nike_limpinho[\"tweets\"]:\n",
    "    limpao = [] \n",
    "    splitei = tweet.split(\" \")\n",
    "    for palavra in splitei:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            limpao.append(palavra)\n",
    "        elif len(palavra)> 2 and palavra[0]!=\"@\" and palavra[0]!=\"#\" and palavra[:4] !=\"http\":\n",
    "            limpao.append(palavra)\n",
    "    tweet_limpos.append(y.join(limpao))\n",
    "    \n",
    "nike_limpao = pd.DataFrame()\n",
    "nike_limpao[\"tweets\"]= tweet_limpos\n",
    "nike_limpao[\"Relevância\"] = teste[\"Valor_(R(1)_I(0))\"]\n",
    "\n",
    "nike_limpao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.31114149195224e-32"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chute = []\n",
    "a = []\n",
    "b=[]\n",
    "c=[]\n",
    "for frase in nike_limpao[\"tweets\"]:\n",
    "    pR_t= 1\n",
    "    pI_t = 1\n",
    "    y = frase.split(\" \")\n",
    "    for palavra in y:\n",
    "        if palavra in prob_i:\n",
    "            pI_t *= prob_i[palavra]\n",
    "        else:\n",
    "            pI_t *= 1/ (len(palavras)+Irrel)\n",
    "        if palavra in prob_r:\n",
    "            pR_t*= prob_r[palavra]\n",
    "        else:\n",
    "            pR_t *= 1/(len(palavra)+Rel)\n",
    "\n",
    "    PR =( pR*pR_t)\n",
    "    PIR =(pI*pI_t)\n",
    "\n",
    "############\n",
    "# saber o mínimo e o máximo\n",
    "    a.append(PR)\n",
    "    b.append(PIR)\n",
    "    c.append(PR-PIR)\n",
    "    \n",
    "    \n",
    "#############\n",
    "    \n",
    "    if PR >= PIR:\n",
    "        chute.append(1)\n",
    "    else:\n",
    "        chute.append(0)\n",
    "\n",
    "#nike_limpao [\"Chute\"]= chute \n",
    "#nike_limpao\n",
    "range_lista = (abs(max(c)-min(c)))/5\n",
    "min(c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Chute'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2524\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2525\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Chute'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-1d44d73e677b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnike_limpao\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnike_limpao\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Relevância\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnike_limpao\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Chute\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Relevância\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Chute\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mumC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnike_limpao\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnike_limpao\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Relevância\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnike_limpao\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Chute\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Relevância\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Chute\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mzero\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnike_limpao\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnike_limpao\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Relevância\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnike_limpao\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Chute\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Relevância\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Chute\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mzeroC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnike_limpao\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnike_limpao\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Relevância\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnike_limpao\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Chute\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Relevância\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Chute\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1842\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3842\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3843\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3844\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2525\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2527\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Chute'"
     ]
    }
   ],
   "source": [
    "um = nike_limpao.loc[(nike_limpao[\"Relevância\"]==1)&(nike_limpao[\"Chute\"]==1), [\"Relevância\", \"Chute\"]]\n",
    "umC = nike_limpao.loc[(nike_limpao[\"Relevância\"]==0)&(nike_limpao[\"Chute\"]==1), [\"Relevância\", \"Chute\"]]\n",
    "zero = nike_limpao.loc[(nike_limpao[\"Relevância\"]==0)&(nike_limpao[\"Chute\"]==0), [\"Relevância\", \"Chute\"]]\n",
    "zeroC = nike_limpao.loc[(nike_limpao[\"Relevância\"]==1)&(nike_limpao[\"Chute\"]==0), [\"Relevância\", \"Chute\"]]\n",
    "    \n",
    "pos_fal = (len(umC)/len(nike_limpao[\"Relevância\"]))*100\n",
    "pos_ver = (len(um)/len(nike_limpao[\"Relevância\"]))*100\n",
    "neg_ver = (len(zero)/len(nike_limpao[\"Relevância\"]))*100\n",
    "neg_fal= (len(zeroC)/len(nike_limpao[\"Relevância\"]))*100\n",
    "\n",
    "print(\"Porcentagem de positivos falsos: {0}%\".format(pos_fal))\n",
    "print(\"Porcentagem de positivos verdadeiros: {0}%\".format(pos_ver))\n",
    "print(\"Porcentagem de negativos verdadeiros: {0}%\".format(neg_ver))\n",
    "print(\"Porcentagem de negativos falsos: {0}%\".format(neg_fal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "niveis =[]\n",
    "\n",
    "for frase in nike_limpao[\"tweets\"]:\n",
    "    pR_t= 1\n",
    "    pI_t = 1\n",
    "    y = frase.split(\" \")\n",
    "    for palavra in y:\n",
    "        if palavra in prob_i:\n",
    "            pI_t *= prob_i[palavra]\n",
    "        else:\n",
    "            pI_t *= 1/ (len(palavras)+Irrel)\n",
    "        if palavra in prob_r:\n",
    "            pR_t*= prob_r[palavra]\n",
    "        else:\n",
    "            pR_t *= 1/(len(palavra)+Rel)\n",
    "\n",
    "    PR = pR*pR_t\n",
    "    PIR = pI*pI_t\n",
    "    \n",
    "    \n",
    "    if PR-PIR>= min(c) and PR-PIR<min(c)+range_lista:\n",
    "        niveis.append(\"MI\")\n",
    "    elif PR-PIR>= min(c) + range_lista and PR-PIR < min(c) + 2*range_lista:\n",
    "        niveis.append(\"I\")\n",
    "    elif PR-PIR >= min(c) + 2*range_lista and PR-PIR < min(c) + 3*range_lista:\n",
    "        niveis.append(\"N\")\n",
    "    elif PR-PIR>= min(c) + 3*range_lista and PR-PIR<min(c) + 4*range_lista:\n",
    "        niveis.append(\"R\")\n",
    "    else:\n",
    "        niveis.append(\"MR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>Relevância</th>\n",
       "      <th>Níveis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jamiesundays nike looking the white people des...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump weighs nikes kaepernick deal think its t...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rafaelshimunov finally cutting out the nike lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear nike not going boycott you because just s...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lindsaytuten anyone who doesn’t want their nik...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tonestradamus when they start boycotting nike ...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nike makes happy ♥ 💪</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>talibbabb nike makes all nfl jerseys the peopl...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jbarro voters skew old but target consumers sk...</td>\n",
       "      <td>0</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>krisparonto well guess nike and kaepernick7 ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>elijahdaniel this man lit his whole ass backya...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>huffpostpol wait what</td>\n",
       "      <td>0</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wordsmithviv upset with nikes decision feature...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kylekuzma boycotting nike because man that try...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yxungjaziah nike just lost customer</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>had out todayso instead wearing skechersi wore...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>allthatandmoore racists i’m never buying nike ...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rachelemiller kaepernick7 i’m scottish and alw...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>alexhortontx social media awash people using p...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wterrence nike what did colin kaepernick sacfr...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mrdane1982 real quick for the ones the back th...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kristyinca not boycotting out not boycotting n...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bso here how they manipulate their dumb fanbas...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>buying nike</td>\n",
       "      <td>1</td>\n",
       "      <td>MR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rafaelshimunov finally cutting out the nike lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>enhahaha hello yall today spend our money nike</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nike kingjames dicks davidhogg111 csgv newtown...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>meluhnen y’all ready boycott nike over black m...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tmillerpoetry nike about the only word white p...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>claytravis plz stick sports and quit sensation...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>meluhnen y’all ready boycott nike over black m...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>jamesmelville anyone who chucks their nike sho...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>daadvaims breaking nike stocks plummet after t...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>krisparonto well guess nike and kaepernick7 ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>teapainusa due the colinkaepernick nike deal t...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>onlyinbos you plan burning throwing away your ...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>markdice thought nike made shoes not knee pads</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>bakermartin1 still waiting the hugh freeze nik...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>biasandpairs wildedylan claytravis nike you kn...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>jamiesundays nike looking the white people des...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>drugg1st nike perhaps marxism</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>had unfollow few people for their hate nike an...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>degrading all nike gear engaging vigorous card...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>chainbody burnt entire nike collection for the...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>pharaohmunk walking past white people nike’s</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>xadoretiffany racists boycotting nike the leas...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>thedonholly you plan boycotting nike will disp...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>eugenegu how much hatred you have have within ...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>iamtannenbaum took less than hours for nike pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>gabehoff pat tillman sacrificed everything col...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>titus o’neil giving those protesting nike over...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>levesquebri see him please call largo police d...</td>\n",
       "      <td>0</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tellstevens did miss something everyone mad ni...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>hey your “american” that the thought wearing n...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>bet nike celebrating its 30th anniversary the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>capeislsweather uarcee2000 jemelehill they all...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tpvtrevor rip nike due the upcoming conservati...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>marklutchman god bless these police officers f...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>pharaohmunk walking past white people nike’s</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>conservtribune james woods was not going sit a...</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweets  Relevância Níveis\n",
       "0    jamiesundays nike looking the white people des...           1     MI\n",
       "1    trump weighs nikes kaepernick deal think its t...           1     MI\n",
       "2    rafaelshimunov finally cutting out the nike lo...           1     MI\n",
       "3    dear nike not going boycott you because just s...           1     MI\n",
       "4    lindsaytuten anyone who doesn’t want their nik...           1     MI\n",
       "5    tonestradamus when they start boycotting nike ...           1     MI\n",
       "6                                 nike makes happy ♥ 💪           1     MI\n",
       "7    talibbabb nike makes all nfl jerseys the peopl...           1     MI\n",
       "8    jbarro voters skew old but target consumers sk...           0     MI\n",
       "9    krisparonto well guess nike and kaepernick7 ha...           1     MI\n",
       "10   elijahdaniel this man lit his whole ass backya...           1     MI\n",
       "11                               huffpostpol wait what           0     MI\n",
       "12   wordsmithviv upset with nikes decision feature...           1     MI\n",
       "13   kylekuzma boycotting nike because man that try...           1     MI\n",
       "14                 yxungjaziah nike just lost customer           1     MI\n",
       "15   had out todayso instead wearing skechersi wore...           1     MI\n",
       "16   allthatandmoore racists i’m never buying nike ...           1     MI\n",
       "17   rachelemiller kaepernick7 i’m scottish and alw...           1     MI\n",
       "18   alexhortontx social media awash people using p...           1     MI\n",
       "19   wterrence nike what did colin kaepernick sacfr...           1     MI\n",
       "20   mrdane1982 real quick for the ones the back th...           1     MI\n",
       "21   kristyinca not boycotting out not boycotting n...           1     MI\n",
       "22   bso here how they manipulate their dumb fanbas...           1     MI\n",
       "23                                         buying nike           1     MR\n",
       "24   rafaelshimunov finally cutting out the nike lo...           1     MI\n",
       "25      enhahaha hello yall today spend our money nike           1     MI\n",
       "26   nike kingjames dicks davidhogg111 csgv newtown...           1     MI\n",
       "27   meluhnen y’all ready boycott nike over black m...           1     MI\n",
       "28   tmillerpoetry nike about the only word white p...           1     MI\n",
       "29   claytravis plz stick sports and quit sensation...           1     MI\n",
       "..                                                 ...         ...    ...\n",
       "170  meluhnen y’all ready boycott nike over black m...           1     MI\n",
       "171  jamesmelville anyone who chucks their nike sho...           1     MI\n",
       "172  daadvaims breaking nike stocks plummet after t...           1     MI\n",
       "173  krisparonto well guess nike and kaepernick7 ha...           1     MI\n",
       "174  teapainusa due the colinkaepernick nike deal t...           1     MI\n",
       "175  onlyinbos you plan burning throwing away your ...           1     MI\n",
       "176     markdice thought nike made shoes not knee pads           1     MI\n",
       "177  bakermartin1 still waiting the hugh freeze nik...           1     MI\n",
       "178  biasandpairs wildedylan claytravis nike you kn...           1     MI\n",
       "179  jamiesundays nike looking the white people des...           1     MI\n",
       "180                      drugg1st nike perhaps marxism           1     MI\n",
       "181  had unfollow few people for their hate nike an...           1     MI\n",
       "182  degrading all nike gear engaging vigorous card...           1     MI\n",
       "183  chainbody burnt entire nike collection for the...           1     MI\n",
       "184       pharaohmunk walking past white people nike’s           1     MI\n",
       "185  xadoretiffany racists boycotting nike the leas...           1     MI\n",
       "186  thedonholly you plan boycotting nike will disp...           1     MI\n",
       "187  eugenegu how much hatred you have have within ...           1     MI\n",
       "188  iamtannenbaum took less than hours for nike pr...           1     MI\n",
       "189  gabehoff pat tillman sacrificed everything col...           1     MI\n",
       "190  titus o’neil giving those protesting nike over...           1     MI\n",
       "191  levesquebri see him please call largo police d...           0     MI\n",
       "192  tellstevens did miss something everyone mad ni...           1     MI\n",
       "193  hey your “american” that the thought wearing n...           1     MI\n",
       "194  bet nike celebrating its 30th anniversary the ...           1     MI\n",
       "195  capeislsweather uarcee2000 jemelehill they all...           1     MI\n",
       "196  tpvtrevor rip nike due the upcoming conservati...           1     MI\n",
       "197  marklutchman god bless these police officers f...           1     MI\n",
       "198       pharaohmunk walking past white people nike’s           1     MI\n",
       "199  conservtribune james woods was not going sit a...           1     MI\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nike_limpao[\"Níveis\"] = niveis\n",
    "nike_limpao\n",
    "\n",
    "nike_limpao.loc[(nike_limpao[\"Níveis\"]==\"MR\"), [\"Níveis\"]]\n",
    "nike_limpao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## referências\n",
    "https://machinelearningmastery.com/clean-text-machine-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
